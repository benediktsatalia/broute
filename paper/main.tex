\documentclass[11pt,a4paper,notitlepage]{article}
\usepackage{amssymb}
\usepackage{amssymb}
\usepackage{geometry} 
\usepackage{float}
\usepackage{booktabs}
\usepackage{algorithm,algorithmic}
\usepackage{amsmath}
\usepackage{pdflscape}
\usepackage{url}
\usepackage{natbib}
\usepackage{graphicx,color}
\usepackage[utf8]{inputenc}
\usepackage{listings} % for inline code
\usepackage{verbatim}

\allowdisplaybreaks
\geometry{a4paper,left=1in,right=1in,top=1in,bottom=1in}

\newcommand{\ft}{\color{blue}}  % to show changes in revised version (F.T.)

\begin{document}

\title{Benchmark!!1}
\author{
Fabien Tricoire$^{1}$ \\[1ex]
 \small $^1$Institute for Transport and Logistics Management,
 Vienna University of Economics and Business\\
 \small Welthandelsplatz 1, 1020 Vienna, Austria\\
  \small \texttt{fabien.tricoire@wu.ac.at}\\[2ex]
}
\date{}
\maketitle

\begin{abstract}
  bla bla bla
\end{abstract}

\section{Introduction}
\label{sec:intro}

Some languages are easier, but how much performance do we lose by
using them?

Purposes: determine which language we can tell our students to
use to implement routing optimisation routines. Also determine which
language we can use ourselves.

Philosophy: not necessarily the best
implementation in the world, but a reasonably good one, i.e. one we
can expect from an average student. Similar algorithm in various languages.

What we measure: run time of the algorithm only. Everything else
(reading data, building initial solution) is not measured. Currently
Julia, Javascript, Pypy, Numba also measure compilation time.

In order to represent a tour in heuristics we restrict ourselves to
variable-size vectors, since they are necessary in most algorithms for
vehicle routing, for instance to insert or delete a vertex from a
tour.
% This is the reason why we do
% not provide a C implementation. It is of course possible to
% implement variable-size vectors using fixed-size arrays and
% bookkeeping; however this stands directly against our stated purposes
% and philosophy. Moreover, implementing a bug-free, efficient version
% of variable-size vectors is unlikely to result in something better
% than existing libraries.
Inserting and deleting elements in a vector has linear worst-case time
complexity. However, for heuristics it is still usually a good idea to
use vectors rather than, say, linked lists, since neighborhood
exploration typically requires to evaluate many moves then perform
only one of these moves. The complexity of performing a move is thus
secondary and unlikely to be a performance bottleneck. Additionally,
performing certain moves can actually be more efficient using a
vector than using a linked list, e.g. inverting a subsequence.

\subsection{Limitations}
Benchmarks are by definition limited in scope; any given benchmark
measurement is only valid within a certain environment. In our case
such environmental factors include the choice of compilers, compiler
versions, operating system and CPU family. Therefore all results are
to be taken as indicators but not absolute truths. The intent of this
study is not to declare a language the winner because it is
consistently faster than others by a few percents, but rather to
assess what kind of performance losses can be expected by, for
example, using Python instead of C++. OR to assess what kind of
performance gains can be achieved by using a JIT compiler for Python.

\section{The benchmarks}
We consider five different benchmark algorithms that perform tasks
commonly encountered in transport optimization. Together they capture
key aspects of computationally intensive tasks in heuristics and
exact methods for transport optimization, although they do not
necessarily use the most efficient algorithm to solve the problem they
are tackling. Additionally, we believe
that they also capture such aspects for other fields of application
of operations research, such as e.g. scheduling. For the sake of
simplicity, we consider the symmetric travelling salesperson problem
(TSP) as a base problem, i.e. input data are in the form of a
symmetric distance matrix while a solution is a permutation. However
some benchmark algorithms solve different problems than the TSP based on these
TSP data, as described below.

All five benchmarking algorithms described below are deterministic.
Additionally, the input provided to them is also deterministic,
i.e. each implementation receives the exact same inputs and performs
the same operations from these inputs. For that purpose, we generate
various instance files, each with a given size $n$, which represents
the number of vertices in the graph, and a number $p$ of
permutations. A permutation is a solution to the TSP.
Vertex coordinates are generated randomly in $[0, 100)$. Let $d_{ij}$
be the Euclidean distance between $i$ and $j$, then the distance
considered is $c_{ij} = \lfloor 100 d_{ij} \rfloor$. Since it is an
integer number, it is sufficient to use integer number representation
to compute the cost of a TSP solution; however certain benchmarks use
floating-point number representation, as explained below.
Each instance
file contains one $n \times n$ distance matrix as well as $p$ randomly
generated permutations, which are used as starting \emph{seeds} for
the algorithms (e.g. as starting solution for 2-opt).

Since the same instance files are given to 
each implementation, all implementations perform the same operations
and return the same result. In order to control result integrity we use a
mechanism similar to \emph{checksum}. The checksum calculation for
applying a certain algorithm using a given permutation as starting seed differs
based on the algorithm and is explained separately for each algorithm
below. The checksum calculation for an instance file is the sum of
checksum values over all permutations in that instance file.

Performances are measured per instance file, i.e. each time reported
is for running an algorithm $p$ times, using one distance matrix with the $p$
different seed permutations.

\subsection{2-opt}
The 2-opt heuristic was first described by~\cite{2-opt}.
One of the most commonly used heuristics in vehicle routing, 2-opt
improves a tour by performing 2-exchanges. A 2-exchange consists in
removing two edges from a tour and reconnecting the tour with two
other edges. It is equivalent to inverting a sub-sequence of the
tour, and can be performed in place using an array or vector solution
representation. If the distances are symmetric, then each move can be
evaluated in constant time. 

The checksum for a given permutation seed is calculated as the number of
improvements found while applying first-improvement 2-opt until no
improving move exists, using this permutation as starting solution.

\subsection{Or-opt}
Or-opt is a heuristic that was first introduced by~\cite{Or-opt}.
It relies on the exploration of a neighborhood that is a subset of all
3-exchanges. A 3-exchange consists in removing 3 edges from a tour and
reconnecting the tour in a different way. Of all these moves, Or-opt
only considers those that shift a sequence of 1, 2 or 3 vertices to a
different position in the tour. Each move can be evaluated in constant time. 

The checksum for a given permutation seed is calculated as the number of
improvements found while applying first-improvement Or-opt until no
improving move exists, using this permutation as starting solution.

\subsection{LNS: Large neighbourhood search}
Large neighborhood search (LNS) was originally introduced in
conjunction with constraint programming to solve the vehicle routing
problem with time windows (VRPTW)~\cite{lns}. Since it has been
a very popular method for tackling a wide variety of vehicle routing
problems, see e.g.~\cite{lnschapter}.

LNS iteratively (i) copies the \emph{incumbent} solution, (ii)
destroys the copy by removing some vertices from it, (iii) repairs the
partial solution by re-inserting previously removed customers in it
and (iv) determines whether this newly produced solution becomes the
new incumbent solution or not. The method relies, among other
things, on randomness. This is an issue since we want each benchmark
to be deterministic. To remedy this issue, we design deterministic
schemes for both destroying and repairing stages. For each starting
seed, we apply a certain number of LNS iterations. At each iteration,
the vertices at even indices in the tour are removed. These removed
vertices are stored in a vector in the order in which they were
removed, i.e. from smallest to largest index. Then the cost of each
possible insertion is calculated and the cheapest insertion is
performed. Because removed vertices are stored in a vector, the
algorithm's behaviour in case of same-cost insertions is
deterministic. 

The checksum for a given permutation seed is calculated as the total
cost of insertions performed while applying 10 iterations of LNS using
that permutation as starting solution.

\subsection{Dynamic programming for column generation}
\label{sec:espprc}
Many state-of-the-art exact methods for vehicle routing problems rely
on column generation (see e.g.~\cite{Baldacci:2012survey}). In such
methods, a significant amount of CPU effort is spent solving the
\emph{pricing subproblem}, which differs depending on the problem at
hand but is nonetheless often an elementary shortest path problem with
resource constraints (ESPPRC). While it can be solved heuristically,
in order to establish optimality it eventually needs to be solved
exactly as well. For this benchmark we implement a dynamic
programming algorithm similar to the one by~\cite{feillet:2004exact}
to solve the ESPPRC, albeit without time windows. One difficulty in
this problem stems from the existence of negative-cost cycles in the
graph. 

In order to simulate an environment similar to the one encountered in
column generation for VRPs, we derive an ESPPRC instance from each TSP
solution by using an auxilliary distance matrix $c'$ from the
distance matrix $c$, as follows:
\begin{enumerate}
\item For each vertex $j$, let $\pi_j$ be the cost of arc $(i, j)$,
  where $i$ is the predecessor of $j$ in the TSP solution.
\item For each arc $(i, j)$, set $c'_{ij}$ to $c_{ij} - d_j$.
\end{enumerate}
Additionally, we generate resource consumption as follows: we consider
6 resources numbered from 0 to 5, and any vertex $i$ consumes resource
$r$ iff the $r^{th}$ bit of $i$'s binary representation is 1
(considering that the first bit is bit 0). That is, in C syntax, iff
\verb|i & (1 << r) > 0|. Capacity is set to 1 for each resource.
The algorithm then computes the elementary shortest path with resource
constraints on $c'$ from 0 to 0 (1 to 1 in Julia).

For this benchmark, floating-point numbers are used to represent cost,
even though the values are integer. This is to emulate the usual
setting when solving such problems.

Each label needs (i) a reference to its predecessor, so that
paths can be reconstructed and (ii) a collection of references to
its successors, in order to recursively propagate dominance and later
ignore labels that are successors of an already proved-to-be-dominated
label. Rust does not allow that, at least not in the intuitive way
where a label is encapsulated in a \verb|struct|, including references
to predecessor and successors. This is because Rust is focused on
security, while this type of construct can lead to unsafe operations if
not used properly. This means that this benchmark cannot be
implemented with Rust, even though it is consistent and reliable with all
other implementations. In order to remediate this issue, we also
implement a second benchmark to implement the same algorithm, although
in a less intuitive way: all labels are stored in a collection, and
the indices in this collection are used in other collections to store all
predecessors and successors. This second implementation represents a
different benchmark, which we call \emph{espprc-index}, whereas the
base benchmark is called \emph{espprc}. The version with indices is more
tedious to implement, but it may also be more efficient, so we also
implement it in other languages.

The checksum for a given permutation seed is the cost of the shortest
elementary path obtained when using that permutation seed to generate the
ESPPRC instance, truncated to its integer part.

\subsection{Maximum flow problem}
Another popular framework for the exact solution of routing
problems is \emph{branch and cut}. Branch and cut is typically applied
to solve mixed-integer linear programs; it is akin to branch and bound
but only considers a subset of all constraints explicitly. Other
constraints are generated dynamically when they are found to be
violated while exploring the search tree. These constraints are said
to be \emph{separated}. One early success story of branch and cut is
actually in application to the symmetric TSP~\citep{padberg:532}, by
separating subtour elimination constraints. The separation procedure
involves finding a minimum capacity cut, which itself involves solving
a maximum flow problem. For this reason the maximum flow problem is
important in vehicle routing, and we dedicate one benchmark to solving
it. The \emph{maxflow} benchmark implements the Edmonds-Karp
algorithm~\cite{edmonds-karp}, which is a specific version of the
Ford-Fulkerson~\cite{ford-fulkerson} augmenting path method. The
specificity resides in how the augmenting paths are generated.

We derive a capacity graph $C$ from the distance matrix $c$ and a
given TSP solution as follows: 
\begin{enumerate}
\item For each vertex $j$, let $t_j$ be the cost of arc $(i, j)$,
  where $i$ is the predecessor of $j$ in the TSP solution.
\item For each arc $(i, j)$, set $C_{ij}$ to $c_{ij}/1000$ if $c_{ij}
  > t_j$, otherwise set it to 0.
\end{enumerate}

For any starting seed, the capacity graph is generated then the
Edmonds-Karp algorithm is applied with 0 as \emph{source} and every other
node as \emph{sink}. The checksum for that permutation seed is the sum
of all maximum flow values thus obtained, truncated to its integer part.

The reason why capacity values are distance values divided by 1000 is
that otherwise, checksum values can exceed the largest possible
integer representation with 32 bits, which can be a problem with some
languages. This means that floating-point numbers are used, which is
representative of the use case of branch and cut for vehicle routing problems.

\section{Languages and implementations considered}
We consider six different programming languages: C++, Python, Java,
Julia, Rust and Javascript. Any rule of selection
is arbitrary in nature; however, we indicate below, for each of these
languages, the main reasons behind their selection. It is possible to
add other languages to this list in the future.

For each language, we may consider multiple \emph{implementations},
which differ by which mechanisms or library they use. For
instance with Python we can compare an implementation using native
lists against an implementation using Numpy arrays. Implementations are
detailed individually below for each language. The code for all
implementations can be found at
\url{https://github.com/fa-bien/routing-benchmark}.

\subsection{C++}
Two implementations: c++14 vs c++98.

Flat vs nested matrix.

static arrays too.

\subsection{Python}
Python vs Pypy vs Numpy vs Numba.
Flat vs nested matrix.

\subsection{Java}
Flat vs nested matrix.
static arrays too.

\subsection{Julia}
General performance tips: read the specific doc section! One unique
official document outlines how to write efficient code. there is also
an automated tool for that.

Flat vs nested matrix.

\subsection{Rust}

\subsection{JavaScript}
JavaScript is not expected to perform as well as, say, C++. However
there are several reasons why it can be appealing to implement routing
algorithms in JavaScript:
\begin{itemize}
\item Any program written in JavaScript can run on virtually any
  computer with a modern web browser, including smartphones.
\item Integrating JavaScript with a web interface is especially easy.
\item JavaScript engines have received considerable attention from
  major companies and are the subject of fierce competition on
  performance. As a result they have seen vast performance
  improvements over the years and the trend is likely to continue.
\end{itemize}

We use Node.js, which allows to run JavaScript programs from the
command line. This means that there is in fact not even the need for a
web browser. Node.js currently uses Google Chrome v8's JavaScript
engine~\cite{nodejs}.

Flat vs nested.

\subsection{Considerations on how to implement a distance matrix}
Perhaps the most straightforward way to implement a distance matrix in
a number of languages is to use nested arrays, i.e. each element of the
main array is an array representing a row of the distance matrix. This
is typically done in C++, Java, Python (although the structure is
officially called a \emph{list} and not an array), Javascript. C and
C++ use pointers to achieve that effect. All these languages use the
same C syntax for looking up values in the distance matrix: the
distance between vertices $i$ and $j$ using distance matrix $d$ is
written \lstinline{d[i][j]}.

Another easy way to implement a distance matrix is to use what we
call from here on a \emph{flat} distance matrix representation, which
is a single-dimensional array containing all distance values. Assuming
indices start at 0, the distance from $i$ to $j$ in array $d$ can be
coded as \lstinline{d[i*n+j]}, where $n$ is the total number of
vertices. This representation guarantees that the whole distance
matrix is stored in contiguous memory. Additionally, looking up in
arrays also takes time, so one lookup is better than two. The drawback
is that we have to pay a multiplication and an addition for each
lookup, and that lookups have to be wrapped in a function call for the
sake of readability. Such function calls can usually be inlined,
i.e. the function content is substituted to the function call, so
there should be no runtime penalty from using a function call. In
general we expect a speedup from using a flat representation. We
implemented some of the benchmarks with both flat and nested matrix
representation in order to determine if there are significant
performance differences.

There are a few cases where the above considerations on using a flat
representation do not apply: Python does not allow inlining, while
Numpy and Julia provide multi-dimensional arrays. Nonetheless we also
wrote a flat matrix version of these implementations, in order
to elicit any difference in performance. 

\subsection{Other general cross-language considerations}
Here we discuss considerations that are subjective in nature, as they
relate to our experience implementing all benchmarks in all
languages. We need to take into account our experience using various
languages prior to the beginning of this work:
\begin{itemize}
\item C++: numerous projects over 20 years.
\item Python: numerous projects over 15 years; no experience of Numpy
  or Numba.
\item Java: PhD work 15 years ago, one minor project 5 years ago.
\item Julia: one ongoing research project started 3 years ago.
\item Javascript: a few hobby projects 5-7 years ago.
\item Rust: no experience at all.
\end{itemize}
To add to the subjectivity, each benchmark was first implemented in
Python then in other languages, with Rust typically being the last one
to be implemented. Therefore the languages implemented last were
supposedly easier, due to increased familiarity with the
algorithm. For all reasons mentioned above, measuring the
time spent implementing each benchmark in each language would be
meaningless, therefore we limit ourselves to subjective opinion here.
Keeping this in mind, we see a subset of perceived
\emph{easy} languages, as in ``easy to program in and get things running
with the expected outcome'', which consists of Python, Julia and
JavaScript. These 
easy languages typically allow to program the same algorithms faster
than the other ones with the same results, performance considerations
aside.
On the other hand, we found the process of getting benchmarks to work
with Rust to be much more tedious than with any other language,
although this is certainly due to lack of experience. Nonetheless, the
JavaScript implementation was typically easier than the C++ or Java ones
despite having more experience with C++ and Java, so
experience does not explain everything.
Ultimately, there is little doubt that any experienced programmer in
any of these languages would have no trouble implementing any of these
benchmarks. Nonetheless, this programmer with experience in mostly C++
and Python implemented every benchmark faster in Python, JavaScript or Julia
than in C++.

We also want to underline that no matter the language, it is possible
to write both efficient and inefficient code. Familiarity and
experience are beneficial; beginners in a language are more likely to
write inefficient code. This being said, not every language is equal
when it comes to documenting how to write efficient code. We note that
the official Julia documentation has a whole section dedicated to that
topic~\cite{julia-performance}. There also exists an automated tool to
detect inefficient code patterns, based on the official
documentation~\cite{julia-traceur}.

\section{Implementation-specific notes}
\subsection{Python}
Python does not allow to inline functions. Since using a flat matrix
requires to wrap matrix value lookup in a function, using a flat distance
matrix in Python is not beneficial. It would of course be possible to
inline by hand, i.e. formulate the correct 1-dimensional index in the
matrix for every lookup, but that would be impractical and defeat the
purposes and philosophy stated in Section~\ref{sec:intro}.
Running Python code that uses a flat representation with a JIT compiler
(e.g. Pypy, Numba) introduces automatic inlining and is likely to
remedy this.

On the ESPPRC benchmark, a label needs to store information about
which customers have already been visited in the partial path it
represents. In Python, preliminary testing reveals that using a set of
integers for that purpose is twice as fast as using a vector of
booleans. Similar preliminary testing in C++ reveals the opposite:
using an array of booleans is faster. This is the behaviour we would
expect in general, the observation on Python are the surprising ones
here. There are two reasons for this expectation: (i) copying an array,
represented in contiguous memory, can in general be performed faster
than copying a set structure and (ii) lookup in an array is performed
in $\mathcal{O}(1)$ while lookup in a set is performed in
$\mathcal{O}(log(n))$.

\subsection{Julia}
Julia has native multi-dimensional arrays, which may be more efficient
than a flat representation. We will determine which version to use
based on experiment. Since Julia's arrays start with index 1, the code
for flat representation lookup of the distance between vertices $i$
and $j$ in matrix $d$ is \lstinline{d[i*n-n+j]}. It is worth noting
that it involves one subtraction on top of the addition and
multiplication used for 0-indexed languages.


Using two threads instead of 1 improves performance by about 10\%,
although it is unclear what the second thread is used for.


\subsection{JavaScript}
All benchmarks are repetitive in nature, as they successively perform similar
operations with different input data. In JavaScript, when our
implementation loads 40 instances and performs the same
benchmarking operations on all 40 them, we observe a significant performance
hit after a few instances (2-5 times slower). In order to remedy this,
we re-start the program individually for each instance. Advanced
knowledge of this specific JavaScript engine might allow to remove that
performance hit, but this is clearly outside the scope of this
study. However it is worth noting that this can be a concern in general.

\subsection{Numba}
Numba is not yet feature-complete for Numpy. A direct consequence is that some
benchmarks cannot be implemented for Numba. For example
\verb|numpy.insert()| is not implemented, but this function is
needed for the $LNS$ benchmark, therefore the $LNS$ benchmark cannot be
implemented with Numba. Additionally, we were not able to implement
the ESPPRC benchmark in a satisfying manner. In our experience, Numba
error messages are sometimes unrelated to the issue causing them, or
too obscure to make sense, keeping in mind the premises of this
paper. It would certainly be possible to implement a dynamic
programming algorithm for the ESPPRC benchmark using Numba's JIT
compilation features, however our conclusion is that it would not be
possible to do so without advanced knowledge of Numba.

Still, Numba is significant enough to be
benchmarked and its current performances are an indication of what to
expect in years to come, as the project matures.

\subsection{Java}
The ecosystem of Java implementations and versions can be hard to
navigate. There exist multiple compilers, multiple virtual
machines, and there is a new Java version every 6 months, sometimes
breaking backwards compatibility. The official reference
implementation is OpenJDK since version 7~\cite{openjdk-reference}.
We use OpenJDK version 11, which is the current long-term support version as
of writing this article.

\subsection{Rust}
As mentioned in Section~\ref{sec:espprc}, Rust does not allow a given
\verb|struct| to have multiple references to the same \verb|struct|
type. For this reason, we needed to develop a different implementation
of the espprc benchmark. In general Rust puts restrictions on what
constitutes valid code, for the sake of safety. This is a valuable
feature in systems programming, which is the main application that Rust was
designed for. This also means that writing code that compiles and runs
is actually a more tedious task, but that once the code compiles,
there is also a higher chance that it will run according to
expectations, like with the Ada programming language for instance.

In the context of this study, these benefits did not appear relevant
however: each benchmark was programmed in all other languages as well,
providing the same results as with the Rust implementation, while no
evidence of memory leak was observed. As mentioned above, The Rust
implementation was typically way more time-consuming than other
implementations, although one reason for that is lack of
experience. Nonetheless, in the context of this study, the generally
assumed benefits of using Rust are not apparent, with the notable
exception of good runtime performance.

\section{Experiments}
All programs are run concurrently on an AMD Ryzen 5 3600 6-Core
Processor at 3.6 GHz with 16 GB RAM running Linux. Twelve threads can
run in parallel, however in our setting at most 5 threads are used at
any given time. For every benchmark and every instance, CPU times are
reported as a ratio of a \emph{reference time} for that benchmark and
instance. In practice, for each benchmark and instance, the reference
time is the time required by the c++98 implementation for that
benchmark and that instance. Therefore the c++98 implementation always
has a CPU ratio of 1.

Mention here compilers and compiler versions used.

\subsection{Impact of using a flat matrix}
\subsection{Impact of using static arrays}
\subsection{A comparison of Python implementations}
\subsection{A comparison of C++ implementations}
Also add a clang++ vs g++ comparison?
\subsection{General cross-language comparison}
\subsection{Cross-language comparison: fast languages}

\subsection{Cross-platform comparison}
We now look at the same benchmarks, using the same languages, but running
in a different environment. We compare runs on an Intel i5-8265U
4-core CPU at 1.6 GHz and on the previously mentioned AMD CPU. The
goal is not to observe which CPU provides the best performance, rather
to determine whether the experimental observations made with one CPU
are valid with the other. For this reason, we stick to reporting CPU
times as a ratio to the CPU time required by the c++98 implementation.

Perhaps also run on WU cluster and observe differences.

\section{Discussion}
The question of what programming language to use when implementing
optimization algorithms is one that, by essence, does not have a final
answer.

\section*{Acknowledgements}
The author is grateful to Sebastian Leitner for his valuable support
in relation with the Rust implementation.

\bibliographystyle{plain}
\bibliography{benchmark}

\end{document}