\documentclass[11pt,a4paper,notitlepage]{article}
\usepackage{amssymb}
\usepackage{amssymb}
\usepackage{geometry} 
\usepackage{float}
\usepackage{booktabs}
\usepackage{algorithm,algorithmic}
\usepackage{amsmath}
\usepackage{pdflscape}
\usepackage{url}
\usepackage{natbib}
\usepackage{graphicx,color}
\usepackage[utf8]{inputenc}
\usepackage{listings} % for inline code

\allowdisplaybreaks
\geometry{a4paper,left=1in,right=1in,top=1in,bottom=1in}

\newcommand{\ft}{\color{blue}}  % to show changes in revised version (F.T.)

\begin{document}

\title{Benchmark!!1}
\author{
Fabien Tricoire$^{1}$ \\[1ex]
 \small $^1$Institute for Transport and Logistics Management,
 Vienna University of Economics and Business\\
 \small Welthandelsplatz 1, 1020 Vienna, Austria\\
  \small \texttt{fabien.tricoire@wu.ac.at}\\[2ex]
}
\date{}
\maketitle

\begin{abstract}
  bla bla bla
\end{abstract}

\section{Introduction}
\label{sec:intro}
Purposes: determine which language we can tell our students to
use to implement routing optimisation routines. Also determine which
language we can use ourselves.

Philosophy: not necessarily the best
implementation in the world, but a reasonably good one, i.e. one we
can expect from an average student. Similar algorithm in various languages.

What we measure: run time of the algorithm only. Everything else
(reading data, building initial solution) is not measured. Currently
Julia also measures compilation time, needs to be fixed.

We restrict ourselves to variable-size vectors, since they are
necessary in most algorithms for vehicle routing, for instance to
insert or delete a vertex from a tour. This is the reason why we do
not provide a C implementation. It is of course possible to
implement variable-size vectors using fixed-size arrays and
bookkeeping; however this stands directly against our stated purposes
and philosophy. Moreover, implementing a bug-free, efficient version
of variable-size vectors is unlikely to result in something better
than existing libraries.

\section{Languages and implementations considered}
\subsection{C++}
Two implementations: c++14 vs c++98.

\subsection{Python}
Python vs Pypy vs Numpy vs Numba.

\subsection{Java}

\subsection{Julia}
General performance tips: read the specific doc section! One unique
official document outlines how to write efficient code.

\subsection{Rust}

\subsection{JavaScript}
JavaScript is not expected to perform as well as, say, C++. However
there are several reasons why it can be appealing to implement routing
algorithms in JavaScript:
\begin{itemize}
\item Any program written in JavaScript can run on virtually any
  computer with a modern web browser, including smartphones.
\item Integrating JavaScript in a web interface is especially easy.
\item JavaScript engines have received considerable attention from
  major companies and are the subject of fierce competition on
  performance. As a result they have seen vast performance
  improvements over the years and the trend is likely to continue.
\end{itemize}

We use Node.js, which allows to run JavaScript programs from the
command line. This means that there is in fact not even the need for a
web browser. Node.js uses Google Chrome v8's JavaScript engine~\cite{nodejs}.

\subsection{General cross-language considerations}
Subjective considerations:
\begin{itemize}
\item Typically easier to program using Python, Julia or JavaScript.
\item Typically harder to program using Rust than anything else but
  might be due to lack of experience. However my experience in
  JavaScript is much lower than in C++ and I still did everything
  faster in JavaScript than in C++.
\end{itemize}

\section{Considered benchmarks and their format}
\subsection{2-opt}
\subsection{Or-opt}
\subsection{Large neighbourhood search}

Note: we use a vector and not a set to store unplanned requests,
otherwise we take the risk of losing determinism.

\subsection{Dynamic programming for ESPPRC}
Motivation: column generation.

Mention here espprc-index and how rust does not allow multiple
references to other labels.

\subsection{Maximum flow problem}
Motivation: branch-and-cut.

\section{Considerations on how to implement a distance matrix}
Perhaps the most straightforward way to implement a distance matrix in
a number of languages is to use nested arrays, i.e. each element of the
main array is an array representing a row of the distance matrix. This
is typically done in C++, Java, Python (although the structure is
officially called a \emph{list} and not an array), Javascript. C and
C++ use pointers to achieve that effect. All these languages use the
same C syntax for looking up values in the distance matrix: the
distance between vertices $i$ and $j$ using distance matrix $d$ is
written \lstinline{d[i][j]}.

Another easy way to implement a distance matrix is to use what we
call from here on a \emph{flat} distance matrix representation, which
is a single-dimensional array containing all distance values. Assuming
indices start at 0, the distance from $i$ to $j$ in array $d$ can be
coded as \lstinline{d[i*n+j]}, where $n$ is the total number of
vertices. This representation guarantees that the whole distance
matrix is stored in contiguous memory. Additionally, looking up in
arrays also takes time, so one lookup is better than two. The drawback
is that we have to pay a multiplication and an addition for each
lookup, and that lookups have to be wrapped in a function call for the
sake of readability. Such function calls can usually be inlined,
i.e. the function content is substituted to the function call, so
there should be no runtime penalty from using a function call. In
general we expect a speedup from using a flat representation.

There are two cases where the above considerations on using a flat
representation do not apply: Python does not allow inlining and Julia
has native multi-dimensional arrays. This is discussed later.

\section{Implementation-specific notes}
\subsection{Python}
Python does not allow to inline functions. Since using a flat matrix
requires to wrap matrix value lookup in a function, using a flat distance
matrix in Python is not beneficial. It would of course be possible to
inline by hand, i.e. formulate the correct 1-dimensional index in the
matrix for every lookup, but that would be impractical and defeat the
purposes and philosophy stated in Section~\ref{sec:intro}.
Running Python code that uses a flat representation with a JIT compiler
(e.g. Pypy, Numba) introduces automatic inlining and is likely to
remedy this.
\subsection{Julia}
Julia has native multi-dimensional arrays, which may be more efficient
than a flat representation. We will determine which version to use
based on experiment. Since Julia's arrays start with index 1, the code
for flat representation lookup of the distance between vertices $i$
and $j$ in matrix $d$ is \lstinline{d[i*n-n+j]}. It is worth noting
that it involves one subtraction on top of the addition and
multiplication used for 0-indexed languages.


Using two threads instead of 1 improves performance by about 10\%,
although it is unclear what the second thread is used for.


\subsection{JavaScript}
All benchmarks are repetitive in nature, as they successively perform similar
operations with different input data. In JavaScript, when our
implementation loads 40 instances and performs the same
benchmarking operations on all 40 them, we observe a significant performance
hit after a few instances (2-5 times slower). In order to remedy this,
we re-start the program individually for each instance. Advanced
knowledge of this specific JavaScript engine might allow to remove that
performance hit, but this is clearly outside the scope of this
study. However it is worth noting that this can be a concern in general.

\subsection{Numba}
Numba is not yet feature-complete for Numpy. A direct consequence is that some
benchmarks cannot be implemented for Numba. For example
\lstinline{numpy.insert()} is not implemented, but this function is
needed for the $LN$ benchmark. Therefore the $LNS$ benchmark cannot be
implemented with Numba. Still, Numba is significant enough to be
benchmarked and its current performance are an indication of what to
expect in years to come.

\subsection{Java}
Mention inconsistencies between Java versions: code written for Java 8
does not compile with Java 11. Because Pair is not in the API any more.

\subsection{Rust}
Issues:
\begin{itemize}
\item Changing from i32 to i64 is problematic somehow
\item Not possible to have refs to both successors and predecessor in
  Label, hence had to handle indices by hand in specific espprc implementation
\end{itemize}

\section{Other notes}
On the ESPPRC benchmark, a label needs to store information about
which customers have already been visited in the partial path it
represents. In Python, preliminary testing reveals that using a set of
integers for that purpose is twice as fast as using a vector of
booleans. Similar preliminary testing in C++ reveals the opposite:
using an array of booleans is faster. This is the behaviour we would
expect in general, the observation on Python are the surprising ones
here. There are two reasons for this expectation: (i) copying an array,
represented in contiguous memory, can in general be performed faster
than copying a set structure and (ii) lookup in an array is performed
in $\cal{O}(1)$ time while lookup in a set is performed in $\cal{O}(log(n)$.

\section*{Acknowledgements}
Sebastian for advice and help with Rust.

\bibliographystyle{plain}
\bibliography{benchmark}

\end{document}